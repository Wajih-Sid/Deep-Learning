{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Helper Methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import preprocessing\n",
    "from PIL import Image\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import shutil\n",
    "import os\n",
    "import requests\n",
    "import base64\n",
    "import matplotlib.image as mpimg\n",
    "\n",
    "train_directory = os.getcwd() + '/all/train'\n",
    "test_directory = os.getcwd() + '/all/test' \n",
    "\n",
    "\n",
    "def exit():\n",
    "    sys.exit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gathering the image data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing 5 images\n",
      "Processing 5 images\n",
      "CPU times: user 20.2 s, sys: 10.9 s, total: 31.1 s\n",
      "Wall time: 36.5 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "\n",
    "def get_dataset_df():  \n",
    "    cameras = os.listdir(train_directory)\n",
    "    \n",
    "    train_images = []\n",
    "\n",
    "    for camera in cameras:\n",
    "        for fname in sorted(os.listdir(train_directory + '/' + camera)):\n",
    "            train_images.append((camera, fname))\n",
    "\n",
    "    train = pd.DataFrame(train_images, columns=['camera', 'fname'])\n",
    "    all_classes = train['camera'].unique()\n",
    "    \n",
    "    test_images = []\n",
    "    camera_name = 'Unknown'\n",
    "    for image in os.listdir(test_directory):\n",
    "        test_images.append((camera_name, image))\n",
    "\n",
    "    test = pd.DataFrame(test_images, columns=['camera', 'fname'])\n",
    "    test_images = os.listdir(test_directory) \n",
    "    return train, test\n",
    "\n",
    "def _decode_image(filename):\n",
    "    img = mpimg.imread(filename)\n",
    "    return tf.cast(img, tf.float32)\n",
    "    \n",
    "#     image_string = tf.read_file(filename)\n",
    "#     image_decoded = tf.image.decode_jpeg(image_string, channels=3)\n",
    "#     image = tf.cast(image_decoded, tf.float32)\n",
    "#     image_resized = tf.image.resize_images(image, [2000, 2000])\n",
    "\n",
    "    \n",
    "    return image\n",
    "\n",
    "def load_image_data(df, offset=None, size=None):\n",
    "    \n",
    "    training_data = []\n",
    "\n",
    "    \n",
    "    list_of_images = ['{}/{}/{}'.format(train_directory, row['camera'], row['fname']) \n",
    "                      for index, row in df[offset:offset+size].iterrows()\n",
    "                     ]\n",
    "    \n",
    "    init_op = tf.global_variables_initializer()\n",
    "    \n",
    "    target_height = 2432\n",
    "    target_width = 4320\n",
    "    \n",
    "\n",
    "    with tf.Session() as sess:\n",
    "        sess.run(init_op)\n",
    "        coord = tf.train.Coordinator()\n",
    "        threads = tf.train.start_queue_runners(coord=coord)\n",
    "   \n",
    "        print \"Processing %s images\" % len(list_of_images)\n",
    "        \n",
    "        count, threshold = 0 , 10\n",
    "\n",
    "        for i in list_of_images:\n",
    "            \n",
    "            \n",
    "            try:\n",
    "                original_image = _decode_image(i)\n",
    "\n",
    "           \n",
    "                image = tf.image.resize_image_with_crop_or_pad(\n",
    "                    original_image,\n",
    "                    target_height,\n",
    "                    target_width\n",
    "                )\n",
    "\n",
    "                if count == threshold:\n",
    "                    break            \n",
    "\n",
    "\n",
    "                # Convert tensor to numpy array\n",
    "                image_data = np.asarray(image.eval())\n",
    "                \n",
    "                training_data.append(image_data)\n",
    "                \n",
    "                count += 1\n",
    "\n",
    "                \n",
    "            except Exception as e:\n",
    "                print str(e)\n",
    "                print \"Failed on %s\" % count\n",
    "\n",
    " \n",
    "        coord.request_stop()\n",
    "        coord.join(threads)\n",
    "        \n",
    "    return training_data\n",
    "\n",
    "\n",
    "train, test = get_dataset_df()\n",
    "\n",
    "\n",
    "x_train_orig = load_image_data(train, offset=0, size=5)\n",
    "y_train_orig = [row['camera'] for index, row in train[0:5].iterrows()]\n",
    "\n",
    "\n",
    "x_test_orig = load_image_data(train, offset=11, size=5)\n",
    "y_test_orig = [row['camera'] for index, row in train[6:12].iterrows()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "global name 'os' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-8c4d879a56dd>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m \u001b[0mencode_classes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     26\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-2-8c4d879a56dd>\u001b[0m in \u001b[0;36mencode_classes\u001b[0;34m()\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mencode_classes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m     \u001b[0mclasses\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlistdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_directory\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrow\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclasses\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: global name 'os' is not defined"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "import copy\n",
    "import sys\n",
    "from keras.datasets import mnist\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras import backend as K\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "batch_size = 5\n",
    "num_classes = 1\n",
    "epochs = 12\n",
    "\n",
    "class_mapping = {}\n",
    "\n",
    "def encode_classes():\n",
    "    classes = os.listdir(train_directory)\n",
    "    \n",
    "    for index, row in enumerate(classes):\n",
    "        class_mapping[row] = index\n",
    "       \n",
    "        \n",
    "encode_classes()\n",
    "\n",
    "\n",
    "x_train = np.array(copy.deepcopy(x_train_orig))\n",
    "y_train = np.array(copy.deepcopy(y_train_orig))\n",
    "x_test = np.array(copy.deepcopy(x_train_orig))\n",
    "y_test = np.array(copy.deepcopy(y_train_orig))\n",
    "\n",
    "\n",
    "print class_mapping\n",
    "y_train = [class_mapping[x] for x in y_train]\n",
    "y_test = [class_mapping[x] for x in y_test]\n",
    "\n",
    "\n",
    "img_rows, img_cols = 2432, 4320\n",
    "if K.image_data_format() == 'channels_first':\n",
    "    x_train = x_train.reshape(x_train.shape[0], 1, img_rows, img_cols)\n",
    "    x_test = x_test.reshape(x_test.shape[0], 1, img_rows, img_cols)\n",
    "    input_shape = (1, img_rows, img_cols)\n",
    "else:\n",
    "#     x_train = x_train.reshape(x_train.shape[0], img_rows, img_cols, 1)\n",
    "#     x_test = x_test.reshape(x_test.shape[0], img_rows, img_cols, 1)\n",
    "    input_shape = (img_rows, img_cols, 3)\n",
    "\n",
    "    \n",
    "x_train = x_train.astype('float32')\n",
    "x_test = x_test.astype('float32')\n",
    "x_train /= 255\n",
    "x_test /= 255\n",
    "\n",
    "print('x_train shape:', x_train.shape)\n",
    "print(\"Training samples: {}\".format(x_train.shape[0]))\n",
    "print(\"Test samples: {}\".format(x_test.shape[0]))\n",
    "\n",
    "# convert class vectors to binary class matrices\n",
    "y_train = keras.utils.to_categorical(y_train, num_classes)\n",
    "y_test = keras.utils.to_categorical(y_test, num_classes)\n",
    "\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Conv2D(32, kernel_size=(3, 3),activation='relu',input_shape=input_shape))\n",
    "model.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(num_classes, activation='softmax'))\n",
    "\n",
    "model.compile(loss=keras.losses.sparse_categorical_crossentropy,\n",
    "              optimizer=keras.optimizers.Adadelta(),\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing the Model by Fitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 5 samples, validate on 5 samples\n",
      "Epoch 1/1\n"
     ]
    }
   ],
   "source": [
    "%%time \n",
    "import time\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "model.fit(x_train, y_train,\n",
    "          batch_size=batch_size,\n",
    "          epochs=1,\n",
    "          verbose=2,\n",
    "          validation_data=(x_test, y_test))\n",
    "score = model.evaluate(x_test, y_test, verbose=0)\n",
    "print('Test loss: {}'.format(score[0]))\n",
    "print('Test accuracy: {}'.format(score[1]))\n",
    "\n",
    "elapsed_time = time.time() - start_time\n",
    "print(\"Elapsed time: {}\".format(hms_string(elapsed_time)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
